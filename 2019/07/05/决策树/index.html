<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="决策树(Decision_tree)"><meta name="keywords" content="监督学习,Decision_tree,决策树"><meta name="author" content="zhiyong.chen"><meta name="copyright" content="zhiyong.chen"><title>决策树(Decision_tree) | Shadowchenxx</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#一、机器学习中分类和预测算法的评估标准"><span class="toc-number">1.</span> <span class="toc-text">一、机器学习中分类和预测算法的评估标准</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#二、概述"><span class="toc-number">2.</span> <span class="toc-text">二、概述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#三、应用"><span class="toc-number">3.</span> <span class="toc-text">三、应用</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">zhiyong.chen</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">66</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">64</span></a></div></div></div><div id="content-outer"><div class="no-bg" id="top-container"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Shadowchenxx</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="post-info"><div id="post-title">决策树(Decision_tree)</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2019-07-05</time></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h4 id="一、机器学习中分类和预测算法的评估标准"><a href="#一、机器学习中分类和预测算法的评估标准" class="headerlink" title="一、机器学习中分类和预测算法的评估标准"></a>一、机器学习中分类和预测算法的评估标准</h4><ul>
<li>准确率</li>
<li>速度</li>
<li>强壮性</li>
<li>可规模性</li>
<li>可解析性</li>
</ul>
<h4 id="二、概述"><a href="#二、概述" class="headerlink" title="二、概述"></a>二、概述</h4><p>1.什么时决策树/判定树（decision tree）<a id="more"></a></p>
<p>​        决策树是一个类似流程图的树结构：其中，每个内部节点表示一个属性上的测试，每个节点代表属性的输出，每个树叶节点代表类和类的分布。</p>
<p><img src="https://raw.githubusercontent.com/shadowchenxx/markdown_pic/master/pictures/d_tree_2.png" alt="d_tree_2"></p>
<p>2.信息熵(bit)[0-1]</p>
<p>对于一件未知的事情，我们需要了解大量信息，信息量的多少等于不确定性的多少</p>
<p>信息熵可以衡量变量的不确定性，变量的不确定性越大，熵也就越大。</p>
<p>公式如下：<br>$$<br> H(X) = -\sum{P(x)}\log_2{[P(x)]}<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">data=[<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'a'</span>,<span class="string">'a'</span>,<span class="string">'b'</span>]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">data1=np.array(data)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line"><span class="comment">#计算信息熵的方法</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calc_ent</span><span class="params">(x)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">    <span class="string">"""</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line"><span class="string">        calculate shanno ent of x</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line"><span class="string">    """</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">    x_value_list = set([x[i] <span class="keyword">for</span> i <span class="keyword">in</span> range(x.shape[<span class="number">0</span>])])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">    ent = <span class="number">0.0</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">    <span class="keyword">for</span> x_value <span class="keyword">in</span> x_value_list:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">        p = float(x[x == x_value].shape[<span class="number">0</span>]) / x.shape[<span class="number">0</span>]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line">        logp = np.log2(p)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line">        ent -= p * logp</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line">    <span class="keyword">print</span> ent</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line">calc_ent(data1)</span></pre></td></tr></table></figure>

<p>3.决策树中的归纳算法（ID3）</p>
<p>A_信息获取量（information gain）： gain(A) = info(D) - info(A)</p>
<ul>
<li><p>树以代表训练样本的单个节点开始</p>
</li>
<li><p>如果样本在同一个类，成为树叶</p>
</li>
<li><p>所有属性都是分类的，即离散值，连续必须离散化，根据设定的阈值</p>
</li>
<li><p>算法递归形成每个样本判定树，一旦一个属性出现在节点上，就不必在该节点的任何后代上考虑它</p>
<blockquote>
<p>递归划分步骤仅当下列条件之一成立停止</p>
<p>a.给定的几点的所有样本属于同一类</p>
<p>b.没有剩余的属性来进一步划分样本，在此情况下，使用多数表决</p>
</blockquote>
</li>
<li><p>其他算法：C4.5,CART</p>
</li>
</ul>
<p>4.树剪枝叶（overfitting）</p>
<ul>
<li>先剪枝（叶的分类纯度）</li>
<li>后剪枝</li>
</ul>
<p>5.决策树的优缺点</p>
<ul>
<li>优点<ul>
<li>直观，便于理解，小规模数据集有效</li>
</ul>
</li>
<li>缺点<ul>
<li>连续变量不好处理，阈值的设定很容易最后结果</li>
<li>类别比较多时，错误的增加比较快</li>
<li>可规模性一般，大规模数据之上的算法复杂度增加严重</li>
</ul>
</li>
</ul>
<h4 id="三、应用"><a href="#三、应用" class="headerlink" title="三、应用"></a>三、应用</h4><p>有时间再写了吧，概念理解起来都很费时间～🐶</p>
<p><img src="https://raw.githubusercontent.com/shadowchenxx/markdown_pic/master/pictures/d_tree_1.png" alt="d_tree_1"></p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined" target="_blank" rel="noopener">zhiyong.chen</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="/http:/yoursite.com/2019/07/05/%E5%86%B3%E7%AD%96%E6%A0%91/">http://yoursite.com/2019/07/05/%E5%86%B3%E7%AD%96%E6%A0%91/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">监督学习</a><a class="post-meta__tags" href="/tags/Decision-tree/">Decision_tree</a><a class="post-meta__tags" href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/">决策树</a></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2019/07/05/matplotlib%E5%B8%B8%E8%A7%81%E7%94%A8%E6%B3%95/"><i class="fa fa-chevron-left">  </i><span>matplotlib学习记录</span></a></div><div class="next-post pull-right"><a href="/2019/07/04/Pandas%E9%80%9F%E6%9F%A5%E6%89%8B%E5%86%8C/"><span>Pandas速查手册</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2019 By zhiyong.chen</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script></body></html>